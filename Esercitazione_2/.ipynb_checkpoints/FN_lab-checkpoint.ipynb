{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FrameNet API in nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Error loading framenet: Package 'framenet' not found in\n",
      "[nltk_data]     index\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('framenet')\n",
    "from nltk.corpus import framenet as fn\n",
    "from nltk.corpus.reader.framenet import PrettyList\n",
    "\n",
    "from operator import itemgetter\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Credits\n",
    "\n",
    "- Collin F. Baker, Nathan Schneider, Miriam R. L. Petruck, and Michael Ellsworth. Tutorial *Getting the Roles Right: Using FrameNet in NLP* tenuto presso la North American Chapter of the Association for Computational Linguistics - Human Language Technology (NAACL HLT 2015), \n",
    "    - http://naacl.org/naacl-hlt-2015/tutorial-framenet.html \n",
    "- documentazione NLTK, \n",
    "    - https://www.nltk.org/api/nltk.corpus.reader.html "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Documentazione all'URL [https://www.nltk.org/api/nltk.corpus.reader.html](https://www.nltk.org/api/nltk.corpus.reader.html)\n",
    "\n",
    "- nltk.corpus.reader.framenet module, Corpus reader for the FrameNet 1.7 lexicon and corpus.\n",
    "\n",
    "#### API Entry Points \n",
    "```\n",
    "    frames([nameRegex])\n",
    "    frame(exactName)\n",
    "    frames_by_lemma(lemmaRegex)\n",
    "\n",
    "    lus([nameRegex])\n",
    "    fes([nameRegex])\n",
    "\n",
    "    semtypes()\n",
    "    propagate_semtypes()\n",
    "\n",
    "    frame_relations([frame, [frame2,]] [type]) frame_relation_types()\n",
    "    fe_relations()\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pretty{List,Dict}\n",
    "```\n",
    "    >>> fn.frames('noise')\n",
    "    [<frame ID=801 name=Cause_to_make_noise>, <frame ID=60 name=Motion_noise>, ...]\n",
    "    >>> type(fn.frames('noise'))\n",
    "    <class 'nltk.corpus.reader.framenet.PrettyList'>\n",
    "```\n",
    "\n",
    "PrettyList does 2 things: \n",
    "- limits the number of elements shown, and suppresses printing of their full details\n",
    "    - Otherwise, it is just a list\n",
    "- Similarly, PrettyDict suppresses printing of its values' details "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "LookupError",
     "evalue": "\n**********************************************************************\n  Resource \u001b[93mframenet_v17\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('framenet_v17')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mcorpora/framenet_v17\u001b[0m\n\n  Searched in:\n    - '/home/ludov/nltk_data'\n    - '/usr/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n**********************************************************************\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/nltk/corpus/util.py\u001b[0m in \u001b[0;36m__load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     82\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m                     \u001b[0mroot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"{}/{}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubdir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzip_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/nltk/data.py\u001b[0m in \u001b[0;36mfind\u001b[0;34m(resource_name, paths)\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0mresource_not_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"\\n%s\\n%s\\n%s\\n\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 583\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource_not_found\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    584\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93mframenet_v17\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('framenet_v17')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mcorpora/framenet_v17.zip/framenet_v17/\u001b[0m\n\n  Searched in:\n    - '/home/ludov/nltk_data'\n    - '/usr/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n**********************************************************************\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-189b58b52eba>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr'(?i)medical'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/nltk/corpus/util.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, attr)\u001b[0m\n\u001b[1;32m    118\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"LazyCorpusLoader object has no attribute '__bases__'\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m         \u001b[0;31m# This looks circular, but its not, since __load() changes our\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0;31m# __class__ to something new:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/nltk/corpus/util.py\u001b[0m in \u001b[0;36m__load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     83\u001b[0m                     \u001b[0mroot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"{}/{}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubdir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzip_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0;31m# Load the corpus.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/nltk/corpus/util.py\u001b[0m in \u001b[0;36m__load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     78\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m                 \u001b[0mroot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"{}/{}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubdir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mLookupError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/nltk/data.py\u001b[0m in \u001b[0;36mfind\u001b[0;34m(resource_name, paths)\u001b[0m\n\u001b[1;32m    581\u001b[0m     \u001b[0msep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"*\"\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m70\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0mresource_not_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"\\n%s\\n%s\\n%s\\n\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 583\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource_not_found\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    584\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93mframenet_v17\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('framenet_v17')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mcorpora/framenet_v17\u001b[0m\n\n  Searched in:\n    - '/home/ludov/nltk_data'\n    - '/usr/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n**********************************************************************\n"
     ]
    }
   ],
   "source": [
    "print(fn.frames(r'(?i)medical'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(fn.frames('Medical_specialties'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = fn.frame(256)\n",
    "f.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_sep():\n",
    "    print('\\n_________________________________________________________\\n\\n')\n",
    "\n",
    "f = fn.frame_by_name('Medical_specialties')\n",
    "print(f)\n",
    "print_sep()\n",
    "print(fn.frame_by_name('Perception'))\n",
    "print_sep()\n",
    "print(fn.frame_by_name('Complaining'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Struttura interna del frame\n",
    "\n",
    "The dict that is returned from the `frame` function will contain the\n",
    "        following information about the Frame:\n",
    "\n",
    "        - 'name'       : the name of the Frame (e.g. 'Birth', 'Apply_heat', etc.)\n",
    "        - 'definition' : textual definition of the Frame\n",
    "        - 'ID'         : the internal ID number of the Frame\n",
    "        - 'semTypes'   : a list of semantic types for this frame\n",
    "           - Each item in the list is a dict containing the following keys:\n",
    "              - 'name' : can be used with the semtype() function\n",
    "              - 'ID'   : can be used with the semtype() function\n",
    "\n",
    "        - 'lexUnit'    : a dict containing all of the LUs for this frame.\n",
    "                         The keys in this dict are the names of the LUs and\n",
    "                         the value for each key is itself a dict containing\n",
    "                         info about the LU (see the lu() function for more info.)\n",
    "\n",
    "        - 'FE' : a dict containing the Frame Elements that are part of this frame\n",
    "                 The keys in this dict are the names of the FEs (e.g. 'Body_system')\n",
    "                 and the values are dicts containing the following keys\n",
    "              - 'definition' : The definition of the FE\n",
    "              - 'name'       : The name of the FE e.g. 'Body_system'\n",
    "              - 'ID'         : The id number\n",
    "              - '_type'      : 'fe'\n",
    "              - 'abbrev'     : Abbreviation e.g. 'bod'\n",
    "              - 'coreType'   : one of \"Core\", \"Peripheral\", or \"Extra-Thematic\"\n",
    "              - 'semType'    : if not None, a dict with the following two keys:\n",
    "                 - 'name' : name of the semantic type. can be used with\n",
    "                            the semtype() function\n",
    "                 - 'ID'   : id number of the semantic type. can be used with\n",
    "                            the semtype() function\n",
    "              - 'requiresFE' : if not None, a dict with the following two keys:\n",
    "                 - 'name' : the name of another FE in this frame\n",
    "                 - 'ID'   : the id of the other FE in this frame\n",
    "              - 'excludesFE' : if not None, a dict with the following two keys:\n",
    "                 - 'name' : the name of another FE in this frame\n",
    "                 - 'ID'   : the id of the other FE in this frame\n",
    "\n",
    "        - 'frameRelation'      : a list of objects describing frame relations\n",
    "        - 'FEcoreSets'  : a list of Frame Element core sets for this frame\n",
    "           - Each item in the list is a list of FE objects\n",
    "\n",
    "        :param fn_fid_or_fname: The Framenet name or id number of the frame\n",
    "        :type fn_fid_or_fname: int or str\n",
    "        :param ignorekeys: The keys to ignore. These keys will not be\n",
    "            included in the output. (optional)\n",
    "        :type ignorekeys: list(str)\n",
    "        :return: Information about a frame\n",
    "        :rtype: dict\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f)\n",
    "# print(len(f.lexUnit))\n",
    "print_sep()\n",
    "print(sorted([x for x in f.FE]))\n",
    "print_sep()\n",
    "print(f.frameRelations)\n",
    "print_sep()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also search for Frames by their Lexical Units (LUs). The **frames_by_lemma()** function returns a list of all frames that contain LUs in which the 'name' attribute of the LU matches the given regular expression. Note that LU names are composed of \"lemma.POS\", where the \"lemma\" part can be made up of either a single lexeme (e.g. 'run') or multiple lexemes (e.g. 'a little') (see below)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(fn.frames_by_lemma(r'(?i)epidemiol'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_list = PrettyList(fn.frames(r'(?i)crim'), maxReprSize=0, breakLines=True)\n",
    "frame_list.sort(key=itemgetter('ID'))\n",
    "\n",
    "for f in frame_list:\n",
    "    print('======================\\nNAME: ' + str(f.name))\n",
    "    print('======================\\nDEF:  ' + str(f.definition))\n",
    "    print('======================\\nFEs:  ' + str(f.FE))\n",
    "    print('======================\\nLUs:  ' + str(f.lexUnit))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Also see the ``frame()`` function for details about what is\n",
    "    contained in the dict that is returned.\n",
    "\"\"\"\n",
    "\n",
    "f = fn.frame_by_id(256)\n",
    "\n",
    "print('NAME: {}[{}]\\tDEF: {}'.format(f.name, f.ID, f.definition))\n",
    "\n",
    "print('\\n____ FEs ____')\n",
    "FEs = f.FE.keys()\n",
    "for fe in FEs:\n",
    "    fed = f.FE[fe]\n",
    "    print('\\tFE: {}\\tDEF: {}'.format(fe, fed.definition))\n",
    "    # print(fed.definition)\n",
    "    \n",
    "print('\\n____ LUs ____')\n",
    "LUs = f.lexUnit.keys()\n",
    "for lu in LUs:\n",
    "    print(lu)\n",
    "\n",
    "#    print('\\tFE-DEF: ' + fe.definition)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lexical Units\n",
    "\n",
    "A lexical unit (LU) is a pairing of a word with a meaning. For example, the \"Apply_heat\" Frame describes a common situation involving a Cook, some Food, and a Heating Instrument, and is _evoked_ by words such as bake, blanch, boil, broil, brown, simmer, steam, etc. These frame-evoking words are the LUs in the Apply_heat frame. Each sense of a polysemous word is a different LU.\n",
    "\n",
    "We have used the word \"word\" in talking about LUs. The reality is actually rather complex. When we say that the word \"bake\" is polysemous, we mean that the lemma \"bake.v\" (which has the word-forms \"bake\", \"bakes\", \"baked\", and \"baking\") is linked to three different frames:\n",
    "\n",
    "- Apply_heat: \"Michelle baked the potatoes for 45 minutes.\"\n",
    "- Cooking_creation: \"Michelle baked her mother a cake for her birthday.\"\n",
    "- Absorb_heat: \"The potatoes have to bake for more than 30 minutes.\"\n",
    "\n",
    "These constitute three different LUs, with different definitions.\n",
    "\n",
    "Framenet provides multiple annotated examples of each sense of a word (i.e. each LU). Moreover, the set of examples (approximately 20 per LU) illustrates all of the combinatorial possibilities of the lexical unit.\n",
    "\n",
    "Each LU is linked to a Frame, and hence to the other words which evoke that Frame. This makes the FrameNet database similar to a thesaurus, grouping together semantically similar words.\n",
    "\n",
    "In the simplest case, frame-evoking words are verbs such as \"fried\" in:\n",
    "\n",
    "\"Matilde fried the catfish in a heavy iron skillet.\"\n",
    "Sometimes event nouns may evoke a Frame. For example, \"reduction\" evokes \"Cause_change_of_scalar_position\" in:\n",
    "\n",
    "\"...the reduction of debt levels to $665 million from $2.6 billion.\"\n",
    "Adjectives may also evoke a Frame. For example, \"asleep\" may evoke the \"Sleep\" frame as in:\n",
    "\n",
    "\"They were asleep for hours.\"\n",
    "\n",
    "Many common nouns, such as artifacts like \"hat\" or \"tower\", typically serve as dependents rather than clearly evoking their own frames.\n",
    "\n",
    "Details for a specific lexical unit can be obtained using this class's lus() function, which takes an optional regular expression pattern that will be matched against the name of the lexical unit:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(fn.lus(r'(?i)a little'))\n",
    "print(fn.lus(r'foresee'))\n",
    "\n",
    "print(fn.frames_by_lemma(r'(?i)little'))\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "quante LUs sono presenti in FN??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(fn.lus()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "consideriamo la LU di `foresee.v`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(fn.lu(256).frame.name)\n",
    "print(fn.lu(256).definition)\n",
    "print(fn.lu(256).lexemes[0].name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Vendetta!\n",
    "\n",
    "Immaginiamo di accedere al frame 'Revenge'. Prima visualizziamo tutto il suo contenuto, e poi accediamo a Frame Elements (FEs) e Lexical Units (LUs).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = fn.frame('Revenge')\n",
    "\n",
    "print(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f.FE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "è possibile inoltre vedere la definzione associata a un certo FE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.FE['Injury'].definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "elenco delle LUs del frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.lexUnit.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "selezione di tutti i frame che hanno un FE che ha a che fare con 'location':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn.fes('location')\n",
    "\n",
    "{fe.name for fe in fn.fes(\"location\")}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "e per ciascuno dei FEs che ha a che fare con 'location' possiamo risalire al relativo Frame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fe in fn.fes(\"location\"):\n",
    "    print(fe.frame.name + '.' + fe.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frame relations\n",
    "\n",
    "Elenco delle possibili relazioni fra frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import re\n",
    "import sys\n",
    "\n",
    "def get_fn_relations(fn_rel_list):\n",
    "    frame_rels = []\n",
    "\n",
    "    for f in fn_rel_list:\n",
    "        text = str(f)\n",
    "        try:\n",
    "            found = re.search('.*-- (.+?) ->.*', text).group(1)\n",
    "            # print(found)\n",
    "            frame_rels.append(found)\n",
    "        except AttributeError:\n",
    "            print('the expression \\n\\t{}\\n does not contain the searched pattern'.format(f))\n",
    "            sys.exit(1)\n",
    "    \n",
    "    # rels_set = set(frame_rels)\n",
    "    # print(rels_set)\n",
    "    return set(frame_rels)\n",
    "\n",
    "fn_rels = get_fn_relations(fn.frame_relations())\n",
    "for fr in fn_rels:\n",
    "    print('\\t' + fr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Possibile utilizzo: che cosa viene causato da 'Make_noise'?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn.frame_relations(frame='Make_noise', type='Causative_of')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "e più in generale, con quali altri frame è in relazione '`Make_noise`'?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rels = fn.frame_relations(frame='Make_noise')\n",
    "for rel in rels:\n",
    "    print(rel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Accesso alle **annotazioni**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_term = 'revenge'\n",
    "count = 0\n",
    "\n",
    "while count < 10:\n",
    "    print(fn.exemplars(input_term)[count].FE)\n",
    "    # print(fn.exemplars(input_term)[count].POS)\n",
    "    print(fn.exemplars(input_term)[count].annotationSet[0])\n",
    "    count += 1\n",
    "    print_sep()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### getFrameSetForStudent\n",
    "\n",
    "Funzione per assegnare a ciascuno un insieme di frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hashlib\n",
    "import random\n",
    "from random import randint\n",
    "from random import seed\n",
    "\n",
    "def print_frames_with_IDs():\n",
    "    for x in fn.frames():\n",
    "        print('{}\\t{}'.format(x.ID, x.name))\n",
    "\n",
    "def get_frams_IDs():\n",
    "    return [f.ID for f in fn.frames()]   \n",
    "\n",
    "def getFrameSetForStudent(surname, list_len=5):\n",
    "    nof_frames = len(fn.frames())\n",
    "    base_idx = (abs(int(hashlib.sha512(surname.encode('utf-8')).hexdigest(), 16)) % nof_frames)\n",
    "    print('\\nstudent: ' + surname)\n",
    "    framenet_IDs = get_frams_IDs()\n",
    "    i = 0\n",
    "    offset = 0 \n",
    "    seed(1)\n",
    "    while i < list_len:\n",
    "        fID = framenet_IDs[(base_idx+offset)%nof_frames]\n",
    "        f = fn.frame(fID)\n",
    "        fNAME = f.name\n",
    "        print('\\tID: {a:4d}\\tframe: {framename}'.format(a=fID, framename=fNAME))\n",
    "        offset = randint(0, nof_frames)\n",
    "        i += 1        \n",
    "\n",
    "\n",
    "getFrameSetForStudent('Zito')\n",
    "getFrameSetForStudent('Ghergo')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
